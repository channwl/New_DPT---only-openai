import streamlit as st
st.set_page_config(page_title="ë””ì§€í„¸ê²½ì˜ ì±—ë´‡", layout="wide")

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents.base import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain_core.runnables import Runnable
from langchain.schema.output_parser import StrOutputParser
from langchain_community.document_loaders import PyMuPDFLoader
import os
import re
import csv
import time
from dotenv import load_dotenv
import openai
import tempfile
import uuid

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° API í‚¤ ì„¤ì •
time.sleep(1)
openai.api_key = st.secrets["openai"]["API_KEY"]
api_key = openai.api_key

# PDF ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (í•œ ë²ˆë§Œ ì‹¤í–‰)
def generate_faiss_index():
    pdf_dir = "data/"
    all_documents = []

    if not os.path.exists(pdf_dir):
        os.makedirs(pdf_dir)
        st.warning("data/ í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ì—¬ê¸°ì— ë„£ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    pdf_files = [file for file in os.listdir(pdf_dir) if file.endswith(".pdf")]
    if not pdf_files:
        st.error("data/ í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. PDFë¥¼ ì¶”ê°€í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    for file_name in pdf_files:
        docs = PDFProcessor.pdf_to_documents(os.path.join(pdf_dir, file_name))
        all_documents.extend(docs)

    chunks = PDFProcessor.chunk_documents(all_documents)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=api_key)
    vector_store = FAISS.from_documents(chunks, embeddings)
    vector_store.save_local("faiss_index_internal")
    st.success(f"{len(pdf_files)}ê°œì˜ PDF íŒŒì¼ë¡œ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ!")

# PDF ì²˜ë¦¬ í´ë˜ìŠ¤
class PDFProcessor:
    @staticmethod
    def pdf_to_documents(pdf_path: str) -> list[Document]:
        loader = PyMuPDFLoader(pdf_path)
        documents = loader.load()
        for d in documents:
            d.metadata['file_path'] = pdf_path
        return documents

    @staticmethod
    def chunk_documents(documents: list[Document]) -> list[Document]:
        splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        return splitter.split_documents(documents)

# RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤ (ì‚¬ì „ ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°)
class RAGSystem:
    def __init__(self, api_key: str):
        self.api_key = api_key

    @st.cache_resource
    def get_vector_db(_self):
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=api_key)
        return FAISS.load_local("faiss_index_internal", embeddings, allow_dangerous_deserialization=True)

    def get_rag_chain(self) -> Runnable:
        template = """ì§ˆë¬¸: {question}\n\nì»¨í…ìŠ¤íŠ¸: {context}\n\në‹µë³€ (ë§ˆì§€ë§‰ì— 'ì¶”ê°€ë¡œ ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆë‹¤ë©´ í¸í•˜ê²Œ ë¬¼ì–´ë´ ì£¼ì„¸ìš” ğŸ˜Š'ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”):"""
        prompt = PromptTemplate.from_template(template)
        model = ChatOpenAI(model="gpt-4o", openai_api_key=self.api_key)
        return prompt | model | StrOutputParser()

    def process_question(self, question: str) -> str:
        vector_db = self.get_vector_db()
        retriever = vector_db.as_retriever(search_kwargs={"k": 5})
        context_docs = retriever.invoke(question)
        chain = self.get_rag_chain()
        return chain.invoke({"question": question, "context": context_docs})

# í”¼ë“œë°± ì €ì¥ í•¨ìˆ˜
def save_feedback(feedback_text, rating):
    if feedback_text.strip() != "" or rating > 0:
        with open("feedback_log.csv", mode="a", encoding="utf-8-sig", newline="") as file:
            writer = csv.writer(file)
            writer.writerow([time.strftime('%Y-%m-%d %H:%M:%S'), rating, feedback_text])
        return True
    return False

# ë©”ì¸ ì•± ì‹¤í–‰ í•¨ìˆ˜
def main():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "user_questions" not in st.session_state:
        st.session_state.user_questions = []

    st.title("ğŸ“ ë””ì§€í„¸ê²½ì˜ì „ê³µ AI ì±—ë´‡")
    st.caption("PDF ìë£Œ ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥´ê²Œ í•™ê³¼ ì •ë³´ë¥¼ ì•Œë ¤ë“œë ¤ìš”!")

    if st.button("ğŸ“¥ (ê´€ë¦¬ì) ì¸ë±ìŠ¤ ë‹¤ì‹œ ìƒì„±í•˜ê¸°"):
        generate_faiss_index()

    left_column, mid_column, right_column = st.columns([1.2, 2.5, 1.3])

    with left_column:
        st.subheader("ğŸ“š ì‚¬ìš© ê°€ì´ë“œ")
        st.markdown("""1. ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.<br>2. ë‹µë³€ì„ í™•ì¸í•˜ê³  ì¶”ê°€ ì§ˆë¬¸ë„ ê°€ëŠ¥í•´ìš”.<br>3. í•„ìš” ì‹œ ì˜¤ë¥¸ìª½ì—ì„œ í”¼ë“œë°± ë‚¨ê²¨ì£¼ì„¸ìš”!""", unsafe_allow_html=True)
        st.subheader("ğŸ“‚ PDF ëª©ë¡")
        pdf_files = [file for file in os.listdir("data/") if file.endswith(".pdf")]
        if pdf_files:
            for file in pdf_files:
                st.markdown(f"âœ… {file}")
        else:
            st.info("í˜„ì¬ ë“±ë¡ëœ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    with mid_column:
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                st.markdown(f'''
                    <div style="
                        background-color: #e9f5ff;
                        padding: 12px;
                        border-radius: 20px;
                        margin-bottom: 10px;
                        max-width: 65%;
                        text-align: left;
                        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
                    ">
                    ğŸ’¬ <b>ì§ˆë¬¸:</b> {msg["content"]}
                    </div>
                ''', unsafe_allow_html=True)
            else:
                st.markdown(f'''
                    <div style="
                        background-color: #f8f8f8;
                        padding: 12px;
                        border-radius: 20px;
                        margin-bottom: 10px;
                        margin-left: auto;
                        max-width: 65%;
                        text-align: left;
                        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
                    ">
                    ğŸ¤– <b>ë‹µë³€:</b> {msg["content"]}
                    </div>
                ''', unsafe_allow_html=True)

        prompt = st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”!")

        if prompt:
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.session_state.user_questions.append(prompt)

            rag_system = RAGSystem(api_key)
            with st.spinner("ì§ˆë¬¸ì„ ì´í•´í•˜ëŠ” ì¤‘ì´ì—ìš”! ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ğŸ˜Š"):
                answer = rag_system.process_question(prompt)

            st.session_state.messages.append({"role": "assistant", "content": answer})
            st.rerun()

    with right_column:
        st.subheader("ğŸ“ ì§ˆë¬¸ íˆìŠ¤í† ë¦¬")
        if st.session_state.user_questions:
            with st.expander("ì§€ê¸ˆê¹Œì§€ ì§ˆë¬¸í•œ ë‚´ìš©"):
                for i, q in enumerate(st.session_state.user_questions, 1):
                    st.markdown(f"{i}. {q}")

        st.subheader("ğŸŒŸ ë§Œì¡±ë„ í”¼ë“œë°±")
        rating = st.slider("ë³„ì ìœ¼ë¡œ ë§Œì¡±ë„ë¥¼ ë‚¨ê²¨ì£¼ì„¸ìš”", min_value=0, max_value=5, step=1, format="%dâ­")
        feedback_input = st.text_area("ê°œë°œìì—ê²Œ ì „í•˜ê³  ì‹¶ì€ ë§ì„ ì ì–´ì£¼ì„¸ìš”!")
        if st.button("í”¼ë“œë°± ì œì¶œ"):
            if save_feedback(feedback_input, rating):
                st.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤.")
            else:
                st.warning("ë³„ì  ë˜ëŠ” ì˜ê²¬ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

        if st.session_state.messages:
            chat_log = "ì—­í• ,ë‚´ìš©\n"
            for m in st.session_state.messages:
                role = "ì‚¬ìš©ì" if m["role"] == "user" else "ì±—ë´‡"
                content = m["content"].replace("\n", " ").replace(",", " ")
                chat_log += f"{role},{content}\n"

            st.download_button(
                label="â¬‡ï¸ ëŒ€í™” ê¸°ë¡ ë‹¤ìš´ë¡œë“œ (CSV)",
                data=chat_log.encode("utf-8-sig"),
                file_name="chat_history.csv",
                mime="text/csv"
            )

if __name__ == "__main__":
    main()
