import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents.base import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain_core.runnables import Runnable
from langchain.schema.output_parser import StrOutputParser
from langchain_community.document_loaders import PyMuPDFLoader
from typing import List, Tuple, Dict, Any, Optional
import os
import re
import csv
import time
from dotenv import load_dotenv
import openai
import tempfile
import uuid  # ê³ ìœ  ID ìƒì„±ìš©

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ê²€ì¦ ê°œì„ 
time.sleep(1)  # í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° ì „ì— 1ì´ˆ ëŒ€ê¸°
openai.api_key = st.secrets["openai"]["API_KEY"] #OpenAI API í‚¤ë¥¼ st.secretsì—ì„œ ê°€ì ¸ì™€ api_key ë³€ìˆ˜ì— ì €ì¥
api_key = openai.api_key  # ë³€ìˆ˜ì— ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— ì‚¬ìš©

# ëª¨ë“ˆí™”: PDF ì²˜ë¦¬ ê¸°ëŠ¥ì„ í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬, PDFProcessor í´ë˜ìŠ¤ (PDF ì²˜ë¦¬)
class PDFProcessor:
    @staticmethod # í´ë˜ìŠ¤ì—ì„œ ê°ì²´ë¥¼ ìƒì„±í•˜ì§€ ì•Šê³ , í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë°”ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆë‹¤.
    def pdf_to_documents(pdf_path: str) -> List[Document]:
        """PDF íŒŒì¼ì„ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            loader = PyMuPDFLoader(pdf_path)
            documents = loader.load()
            for d in documents:
                d.metadata['file_path'] = pdf_path
            return documents
        except Exception as e:
            st.error(f"PDF ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") #ì‚¬ìš©ì ì¹œí™”ì  ì‹œìŠ¤í…œ : Streamlitì—ì„œ ì—ëŸ¬ í‘œì‹œí•´ì£¼ê¸°
            return []

    @staticmethod
    def chunk_documents(documents: List[Document]) -> List[Document]:
        """Documentë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• """
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        return text_splitter.split_documents(documents)

    @staticmethod
    def save_to_vector_store(documents: List[Document], index_name: str = "faiss_index") -> bool:
        """Documentë¥¼ ë²¡í„° DBì— ì €ì¥"""
        try:
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=api_key)
            vector_store = FAISS.from_documents(documents, embedding=embeddings)
            vector_store.save_local(index_name)
            return True
        except Exception as e:
            st.error(f"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    @staticmethod
    def process_uploaded_files(uploaded_files) -> bool:
        """ì—…ë¡œë“œëœ PDF íŒŒì¼ ì²˜ë¦¬ ì‘ì—… í†µí•©"""
        if not uploaded_files:
            st.error("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        all_documents = []
        
        # ì—…ë¡œë“œëœ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
        for uploaded_file in uploaded_files:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
                temp_file.write(uploaded_file.getvalue())
                temp_path = temp_file.name
            
            # PDF ë¬¸ì„œ ì¶”ì¶œ
            documents = PDFProcessor.pdf_to_documents(temp_path)
            if documents:
                all_documents.extend(documents)
                st.success(f"{uploaded_file.name} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
            else:
                st.warning(f"{uploaded_file.name} íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_path)
        
        if not all_documents:
            st.error("ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
        
        # ë¬¸ì„œ ë¶„í• 
        smaller_documents = PDFProcessor.chunk_documents(all_documents)
        
        # ì„¸ì…˜ì— ê³ ìœ í•œ ì¸ë±ìŠ¤ ì´ë¦„ ìƒì„± ë˜ëŠ” ì‚¬ìš©
        if "index_name" not in st.session_state:
            st.session_state.index_name = f"faiss_index_{uuid.uuid4().hex[:8]}"
        
        # ë²¡í„° ì €ì¥ì†Œì— ì €ì¥
        success = PDFProcessor.save_to_vector_store(smaller_documents, st.session_state.index_name)
        
        if success:
            st.success(f"ì´ {len(all_documents)}ê°œì˜ ë¬¸ì„œ, {len(smaller_documents)}ê°œì˜ ì²­í¬ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return success

# ëª¨ë“ˆí™”: RAG ì‹œìŠ¤í…œ ê¸°ëŠ¥ì„ í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬
class RAGSystem:
    def __init__(self, api_key: str, index_name: str = "faiss_index"):
        self.api_key = api_key
        self.index_name = index_name
        
    def get_rag_chain(self) -> Runnable:
        """RAG ì²´ì¸ ìƒì„±"""
        template = """
        ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:

        **ì‚¬ìš©ìê°€ í•™ê³¼ ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ë©´, ì•„ë˜ ê·œì¹™ì„ ë”°ë¦…ë‹ˆë‹¤.**

        ì´ í”„ë¡¬í¬íŠ¸ëŠ”, í•™ê³¼ ì±—ë´‡ì„ ìœ„í•œ í”„ë¡¬í¬íŒ…ì´ì•¼.

        1. ì‘ë‹µì€ ìµœëŒ€ 5ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
        2. ëª…í™•í•œ ë‹µë³€ì´ ì–´ë ¤ìš¸ ê²½ìš° **"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤."**ë¼ê³  ë‹µë³€í•©ë‹ˆë‹¤.
        3. ê³µì†í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        4. ì§ˆë¬¸ì— **'ë””ì§€í„¸ê²½ì˜ì „ê³µ'ì´ë¼ëŠ” ë‹¨ì–´ê°€ ì—†ë”ë¼ë„**, ê´€ë ¨ ì •ë³´ë¥¼ PDFì—ì„œ ì°¾ì•„ ë‹µë³€í•©ë‹ˆë‹¤.
        5. ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì—¬, **ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì •ë³´**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        6. í•™ìƒì´ ì¶”ê°€ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆë„ë¡ ë¶€ë“œëŸ¬ìš´ ë§ˆë¬´ë¦¬ ë¬¸ì¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì˜ˆ: â€œë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ í¸í•˜ê²Œ ë¬¼ì–´ë´ !â€)
        7. ëŒ€í™” íë¦„ì„ ìœ ì§€í•˜ê¸° ìœ„í•´, í•™ìƒì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ ê³ ë ¤í•˜ê³  **ì ì ˆí•œ í›„ì† ì§ˆë¬¸ì„ ë˜ì ¸ ë” ê¹Šì´ ìˆëŠ” ëŒ€í™”ë¥¼ ìœ ë„í•©ë‹ˆë‹¤.
        8. ë‚´ìš©ì„ ì‚¬ìš©ìê°€ ì•Œì•„ë³´ê¸° ì‰½ê²Œ ì •ë¦¬í•´ì„œ ë‚˜ì—´í•©ë‹ˆë‹¤.
        9. í•œêµ­ì–´ ì´ì™¸ì˜ ì–¸ì–´ë¡œ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´, ê·¸ ì–¸ì–´ì— ë§ê²Œ ë‹µë³€í•©ë‹ˆë‹¤. (ex. ì˜ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ PDFë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ë‹µë³€)
        10. ì‚¬ìš©ìê°€ ì–´íˆ¬ì˜ ë³€ê²½ì„ ìš”ì²­í•˜ë©´ ë“¤ì–´ì£¼ì§€ ë§ˆì„¸ìš”.
        

        ì»¨í…ìŠ¤íŠ¸: {context}

        ì§ˆë¬¸: {question}

        ì‘ë‹µ:
        """


        custom_rag_prompt = PromptTemplate.from_template(template)
        model = ChatOpenAI(model="gpt-4o", openai_api_key=self.api_key)

        return custom_rag_prompt | model | StrOutputParser()
    
    @st.cache_resource
    def get_vector_db(_self, index_name):  # ì²« ë²ˆì§¸ ì¸ìë¡œ selfë¥¼ ë°›ë˜ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ _selfë¡œ ì´ë¦„ ë³€ê²½
        """ë²¡í„° DB ë¡œë“œ"""
        try:
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=api_key)
            return FAISS.load_local(index_name, embeddings, allow_dangerous_deserialization=True)
        except Exception as e:
            st.error(f"ë²¡í„° DB ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def process_question(self, user_question: str) -> Tuple[str, List[Document]]:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ RAG ì²˜ë¦¬"""
        vector_db = self.get_vector_db(self.index_name)
        if not vector_db:
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", []
            
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        retriever = vector_db.as_retriever(search_kwargs={"k": 10})
        retrieve_docs = retriever.invoke(user_question)
        
        # RAG ì²´ì¸ í˜¸ì¶œ
        chain = self.get_rag_chain()
        
        try:
            response = chain.invoke({"question": user_question, "context": retrieve_docs})
            return response, retrieve_docs
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []

# ëª¨ë“ˆí™”: UI ê´€ë ¨ ê¸°ëŠ¥ì„ í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬
class ChatbotUI:
    @staticmethod
    def natural_sort_key(s):
        """íŒŒì¼ëª… ìì—° ì •ë ¬ í‚¤ ìƒì„±"""
        return [int(text) if text.isdigit() else text for text in re.split(r'(\d+)', s)]
    
    @staticmethod
    def save_feedback(questions: List[Dict], feedbacks: List[Dict]) -> bool:
        """ì‚¬ìš©ì ì§ˆë¬¸ ë° í”¼ë“œë°±ì„ CSVë¡œ ì €ì¥"""
        if not questions and not feedbacks:
            st.warning("ì €ì¥í•  ì§ˆë¬¸ ë˜ëŠ” í”¼ë“œë°± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        try:
            # ì§ˆë¬¸ê³¼ í”¼ë“œë°± í˜•ì‹ í†µì¼ (ë”•ì…”ë„ˆë¦¬/ë¬¸ìì—´ ëª¨ë‘ ì²˜ë¦¬)
            formatted_questions = []
            for q in questions:
                if isinstance(q, dict) and "ì§ˆë¬¸" in q:
                    formatted_questions.append(q["ì§ˆë¬¸"])
                elif isinstance(q, str):
                    formatted_questions.append(q)
                    
            formatted_feedbacks = []
            for f in feedbacks:
                if isinstance(f, dict) and "í”¼ë“œë°±" in f:
                    formatted_feedbacks.append(f["í”¼ë“œë°±"])
                elif isinstance(f, str):
                    formatted_feedbacks.append(f)
            
            # ê¸¸ì´ ë§ì¶”ê¸°
            max_length = max(len(formatted_questions), len(formatted_feedbacks))
            formatted_questions.extend([""] * (max_length - len(formatted_questions)))
            formatted_feedbacks.extend([""] * (max_length - len(formatted_feedbacks)))
            
            # CSV ì €ì¥
            with open("questions_and_feedback.csv", mode="w", encoding="utf-8-sig", newline="") as file:
                writer = csv.writer(file)
                writer.writerow(["ì§ˆë¬¸", "í”¼ë“œë°±"])
                for q, f in zip(formatted_questions, formatted_feedbacks):
                    writer.writerow([q, f])
            return True
            
        except Exception as e:
            st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

def main():
    st.set_page_config(
        initial_sidebar_state="expanded",
        layout="wide",
        page_icon="ğŸ¤–",
        page_title="ë””ì§€í„¸ê²½ì˜ì „ê³µ ì±—ë´‡")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”ë¥¼ í•œê³³ì—ì„œ ì²˜ë¦¬
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "user_questions" not in st.session_state:
        st.session_state.user_questions = []
    if "user_feedback" not in st.session_state:
        st.session_state.user_feedback = []
    # PDF ì²˜ë¦¬ ìƒíƒœ ì¶”ì ìš© ë³€ìˆ˜
    if "pdf_processed" not in st.session_state:
        st.session_state.pdf_processed = False
    # ì¸ë±ìŠ¤ ì´ë¦„ ì €ì¥ìš© ë³€ìˆ˜
    if "index_name" not in st.session_state:
        st.session_state.index_name = f"faiss_index_{uuid.uuid4().hex[:8]}"

    # UI ì´ˆê¸°í™”
    st.header("ë””ì§€í„¸ê²½ì˜ì „ê³µ ì±—ë´‡")

    # ë ˆì´ì•„ì›ƒ
    left_column, mid_column, right_column = st.columns([1, 2, 1])
    
    # ì™¼ìª½ ì—´ - PDF ì—…ë¡œë“œ ë° ì²˜ë¦¬
    with left_column:
        st.subheader("PDF ì—…ë¡œë“œ")
        uploaded_files = st.file_uploader(
            "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš” (ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥)",
            type=["pdf"],
            accept_multiple_files=True
        )
        
        if st.button("ì—…ë¡œë“œí•œ PDF ì²˜ë¦¬í•˜ê¸°", disabled=not uploaded_files):
            with st.spinner("PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                success = PDFProcessor.process_uploaded_files(uploaded_files)
                if success:
                    st.session_state.pdf_processed = True
                    st.success("ëª¨ë“  PDF íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.session_state.pdf_processed = False
                    st.error("PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš© ì„¤ëª…ì„œ
        with st.expander("ì‚¬ìš© ë°©ë²•"):
            st.markdown("""
            1. ì™¼ìª½ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤ (ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥).
            2. 'ì—…ë¡œë“œí•œ PDF ì²˜ë¦¬í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤.
            3. ì¤‘ì•™ì˜ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.
            4. ì±—ë´‡ì€ ì—…ë¡œë“œí•œ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
            5. ìƒˆë¡œìš´ PDFë¡œ ë³€ê²½í•˜ë ¤ë©´ ë‹¤ì‹œ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ì„¸ìš”.
            """)

    # ì¤‘ì•™ ì—´ - ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    with mid_column:
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì…ë ¥ ë° ì²˜ë¦¬
        prompt = st.chat_input("PDF ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.")
        
        if prompt:
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # PDF ì²˜ë¦¬ ìƒíƒœ í™•ì¸ ë¡œì§ ì¶”ê°€
            if not st.session_state.pdf_processed:
                with st.chat_message("assistant"):
                    assistant_response = "ë¨¼ì € ì™¼ìª½ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”."
                    st.markdown(assistant_response)
                    st.session_state.messages.append({"role": "assistant", "content": assistant_response})
            else:
                # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
                rag_system = RAGSystem(api_key, st.session_state.index_name)
                
                # ì§ˆë¬¸ ì²˜ë¦¬ ë° ì‘ë‹µ
                with st.spinner("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        response, context = rag_system.process_question(prompt)
                        with st.chat_message("assistant"):
                            st.markdown(response)
                            if context:
                                # ê´€ë ¨ ë¬¸ì„œ í‘œì‹œ ë°©ì‹ ê°œì„ 
                                with st.expander("ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°"):
                                    for idx, document in enumerate(context, 1):
                                        st.subheader(f"ê´€ë ¨ ë¬¸ì„œ {idx}")
                                        st.write(document.page_content)
                                        
                                        # ë©”íƒ€ë°ì´í„° í‘œì‹œ (íŒŒì¼ ì •ë³´ ë“±)
                                        if document.metadata and 'file_path' in document.metadata:
                                            file_name = os.path.basename(document.metadata['file_path'])
                                            st.caption(f"ì¶œì²˜: {file_name}")
                        
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    except Exception as e:
                        st.error(f"ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    # ì˜¤ë¥¸ìª½ ì—´ - í”¼ë“œë°± ë° ì¶”ê°€ ì§ˆë¬¸
    with right_column:
        # ì„¹ì…˜ ì œëª© ì¶”ê°€ë¡œ UI ëª…í™•ì„± í–¥ìƒ
        st.subheader("ì¶”ê°€ ì§ˆë¬¸ ë° í”¼ë“œë°±")
        
        # ì¶”ê°€ ì§ˆë¬¸ ì„¹ì…˜
        st.text("ì¶”ê°€ ì§ˆë¬¸")
        user_question = st.text_input(
            "ì±—ë´‡ì„ í†µí•´ ì •ë³´ë¥¼ ì–»ì§€ ëª»í•˜ì˜€ê±°ë‚˜ ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì§ˆë¬¸ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!",
            placeholder="ê³¼ëª© ë³€ê²½ or í–‰ì‚¬ ë¬¸ì˜"
        )

        # ë²„íŠ¼ì— key ì¶”ê°€ë¡œ ì¤‘ë³µ ë°©ì§€
        if st.button("ì§ˆë¬¸ ì œì¶œ", key="submit_question"):
            if user_question:
                st.session_state.user_questions.append({"ì§ˆë¬¸": user_question})
                st.success("ì§ˆë¬¸ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
                # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                st.experimental_rerun()
            else:
                st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # í”¼ë“œë°± ì„¹ì…˜
        st.text("")
        st.text("ì‘ë‹µ í”¼ë“œë°±")
        feedback = st.radio("ì‘ë‹µì´ ë§Œì¡±ìŠ¤ëŸ¬ìš°ì…¨ë‚˜ìš”?", ("ë§Œì¡±", "ë¶ˆë§Œì¡±"))

        if feedback == "ë§Œì¡±":
            st.success("ê°ì‚¬í•©ë‹ˆë‹¤! ë„ì›€ì´ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤.")
        elif feedback == "ë¶ˆë§Œì¡±":
            st.warning("ë¶ˆë§Œì¡±í•˜ì‹  ë¶€ë¶„ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤.")
            
            # ë¶ˆë§Œì¡± ì‚¬ìœ  ì…ë ¥
            reason = st.text_area("ë¶ˆë§Œì¡±í•œ ë¶€ë¶„ì´ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.")

            # ë²„íŠ¼ì— key ì¶”ê°€ë¡œ ì¤‘ë³µ ë°©ì§€
            if st.button("í”¼ë“œë°± ì œì¶œ", key="submit_feedback"):
                if reason:
                    st.session_state.user_feedback.append({"í”¼ë“œë°±": reason})
                    st.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                    st.experimental_rerun()
                else:
                    st.warning("ë¶ˆë§Œì¡± ì‚¬ìœ ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

        # ì§ˆë¬¸ ë° í”¼ë“œë°± CSV ì €ì¥
        st.text("")
        
        ui = ChatbotUI()  # UI í´ë˜ìŠ¤ ì´ˆê¸°í™”
        if st.button("ì§ˆë¬¸ ë° í”¼ë“œë°± ë“±ë¡í•˜ê¸°"):
            # ê°œì„ ëœ í”¼ë“œë°± ì €ì¥ í•¨ìˆ˜ ì‚¬ìš©
            if ui.save_feedback(st.session_state.user_questions, st.session_state.user_feedback):
                st.success("ì§ˆë¬¸ê³¼ í”¼ë“œë°±ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # ë“±ë¡ í›„ ëª©ë¡ ì´ˆê¸°í™”
                st.session_state.user_questions = []
                st.session_state.user_feedback = []
                time.sleep(1)
                st.experimental_rerun()

        # ë¬¸ì˜ ì •ë³´
        st.text("")
        st.text("")
        # í…ìŠ¤íŠ¸ë¥¼ markdownìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
        st.markdown("""
        ê³ ë ¤ëŒ€í•™êµ ì„¸ì¢…ìº í¼ìŠ¤ ë””ì§€í„¸ê²½ì˜ì „ê³µ í™ˆí˜ì´ì§€ë¥¼ ì°¸ê³ í•˜ê±°ë‚˜,
        ë””ì§€í„¸ê²½ì˜ì „ê³µ ì‚¬ë¬´ì‹¤(044-860-1560)ì— ì „í™”í•˜ì—¬ ë¬¸ì˜ì‚¬í•­ì„ ì ‘ìˆ˜í•˜ì„¸ìš”.
        """)

if __name__ == "__main__":
    main()

# start : streamlit run app.py
# stop : ctrl + c
