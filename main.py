import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents.base import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain_core.runnables import Runnable
from langchain.schema.output_parser import StrOutputParser
from langchain_community.document_loaders import PyMuPDFLoader
from typing import List, Tuple, Dict, Any, Optional
import os
import re
import csv
import time
import tempfile
import uuid

# OpenAI API í‚¤ ë¡œë“œ
time.sleep(1)
api_key = st.secrets["openai"]["API_KEY"]

# PDF ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (í•œ ë²ˆë§Œ ì‹¤í–‰)
def generate_faiss_index():
    pdf_dir = "data/"
    all_documents = []

    if not os.path.exists(pdf_dir):
        os.makedirs(pdf_dir)
        st.warning("data/ í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ì—¬ê¸°ì— ë„£ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    pdf_files = [file for file in os.listdir(pdf_dir) if file.endswith(".pdf")]
    if not pdf_files:
        st.error("data/ í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. PDFë¥¼ ì¶”ê°€í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    for file_name in pdf_files:
        docs = PDFProcessor.pdf_to_documents(os.path.join(pdf_dir, file_name))
        all_documents.extend(docs)

    chunks = PDFProcessor.chunk_documents(all_documents)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=api_key)
    vector_store = FAISS.from_documents(chunks, embeddings)
    vector_store.save_local("faiss_index_internal")
    st.success(f"{len(pdf_files)}ê°œì˜ PDF íŒŒì¼ë¡œ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ!")

# PDF ì²˜ë¦¬ ê¸°ëŠ¥ í´ë˜ìŠ¤
class PDFProcessor:
    @staticmethod
    def pdf_to_documents(pdf_path: str) -> List[Document]:
        try:
            loader = PyMuPDFLoader(pdf_path)
            documents = loader.load()
            for d in documents:
                d.metadata['file_path'] = pdf_path
            return documents
        except Exception as e:
            st.error(f"PDF ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

    @staticmethod
    def chunk_documents(documents: List[Document]) -> List[Document]:
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        return text_splitter.split_documents(documents)

# RAG ì‹œìŠ¤í…œ (OpenAI ì „ìš©)
class RAGSystem:
    def __init__(self, api_key: str, index_name: str = "faiss_index_internal"):
        self.api_key = api_key
        self.index_name = index_name

    def get_rag_chain(self) -> Runnable:
        template = """
        ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:

        1. ì‘ë‹µì€ ìµœëŒ€ 5ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
        2. ëª…í™•í•œ ë‹µë³€ì´ ì–´ë ¤ìš¸ ê²½ìš° **"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤."**ë¼ê³  ë‹µë³€í•©ë‹ˆë‹¤.
        3. ê³µì†í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        4. ì§ˆë¬¸ì— **'ë””ì§€í„¸ê²½ì˜ì „ê³µ'ì´ë¼ëŠ” ë‹¨ì–´ê°€ ì—†ë”ë¼ë„**, ê´€ë ¨ ì •ë³´ë¥¼ PDFì—ì„œ ì°¾ì•„ ë‹µë³€í•©ë‹ˆë‹¤.
        5. ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì—¬, **ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì •ë³´**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        6. í•™ìƒì´ ì¶”ê°€ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆë„ë¡ ë¶€ë“œëŸ¬ìš´ ë§ˆë¬´ë¦¬ ë¬¸ì¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        7. ë‚´ìš©ì„ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì •ë¦¬í•´ ì¤ë‹ˆë‹¤.
        8. í•œêµ­ì–´ ì™¸ì˜ ì–¸ì–´ë¡œ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ í•´ë‹¹ ì–¸ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.

        ì»¨í…ìŠ¤íŠ¸: {context}

        ì§ˆë¬¸: {question}

        ë‹µë³€:
        """

        custom_rag_prompt = PromptTemplate.from_template(template)
        model = ChatOpenAI(model="gpt-4o", openai_api_key=self.api_key)

        return custom_rag_prompt | model | StrOutputParser()

    @st.cache_resource
    def get_vector_db(_self):
        try:
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=api_key)
            return FAISS.load_local("faiss_index_internal", embeddings, allow_dangerous_deserialization=True)
        except Exception as e:
            st.error(f"ë²¡í„° DB ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

    def process_question(self, user_question: str) -> Tuple[str, List[Document]]:
        vector_db = self.get_vector_db()
        if not vector_db:
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. PDF ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.", []

        retriever = vector_db.as_retriever(search_kwargs={"k": 10})
        retrieve_docs = retriever.invoke(user_question)

        chain = self.get_rag_chain()

        try:
            response = chain.invoke({"question": user_question, "context": retrieve_docs})
            return response, retrieve_docs
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", []

def main():
    st.set_page_config(initial_sidebar_state="expanded", layout="wide", page_icon="ğŸ¤–", page_title="ë””ì§€í„¸ê²½ì˜ì „ê³µ ì±—ë´‡")

    if st.button("ğŸ“¥ (ê´€ë¦¬ì) ì¸ë±ìŠ¤ ë‹¤ì‹œ ìƒì„±í•˜ê¸°"):
        generate_faiss_index()

    if "messages" not in st.session_state:
        st.session_state.messages = []

    st.title("ğŸ“ ë””ì§€í„¸ê²½ì˜ì „ê³µ ì±—ë´‡")

    left_column, mid_column, right_column = st.columns([1, 2, 1])

    with mid_column:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        prompt = st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

        if prompt:
            with st.chat_message("user"):
                st.markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            rag_system = RAGSystem(api_key)

            with st.spinner("ì§ˆë¬¸ì„ ì´í•´í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ğŸ˜Š"):
                response, context = rag_system.process_question(prompt)
                with st.chat_message("assistant"):
                    st.markdown(response)

            st.session_state.messages.append({"role": "assistant", "content": response})
            st.rerun()

    with right_column:
        st.subheader("ğŸ“¢ í”¼ë“œë°± ë‚¨ê¸°ê¸°")
        feedback = st.text_area("ê°œë°œìì—ê²Œ ì „í•˜ê³  ì‹¶ì€ ë§ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”!")

        if st.button("í”¼ë“œë°± ì œì¶œ"):
            if feedback.strip():
                with open("feedback_log.csv", mode="a", encoding="utf-8-sig", newline="") as file:
                    writer = csv.writer(file)
                    writer.writerow([time.strftime('%Y-%m-%d %H:%M:%S'), feedback])
                st.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.warning("í”¼ë“œë°± ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()

